{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b16f03b-6d0f-4eca-997e-773cd540f4c4",
   "metadata": {},
   "source": [
    "# Langchain Agents and LangGraph\n",
    "\n",
    "LLMs become really interesting when we use them in autonomous agents, giving them tools and allowing them to reason with themselves.\n",
    "\n",
    "In this tutorial, I will focus on a relatively simple agent: ReAct.\n",
    "\n",
    "### What is ReAct?\n",
    "ReAct was first introduce in [this paper](https://arxiv.org/abs/2210.03629), and is a simple autonomous agent for answering questions using pre-built function calls.\n",
    "\n",
    "Most agents follow the thought, action, observation pattern. The agent comes up with a thought, then can decide on an action to execute, then receives an observation upon the actions' execution.\n",
    "\n",
    "The ReAct setup is as follows:\n",
    "- Prompt the agent to come up with an action that it can take\n",
    "- Take the action on behalf of the agent, and append the output of the action to the original prompt\n",
    "- Repeat this process until the agent generates an answer.\n",
    "\n",
    "### Where can I go from here?\n",
    "There are many extensions to ReAct:\n",
    "- [LLMCompiler](https://arxiv.org/abs/2312.04511) is a system for generating parallel function calls, which yields speedups over ReAct prompting, with better accuracy on some benchmarks!\n",
    "- [Voyager](https://arxiv.org/abs/2305.16291) is a LLM lifelong learning agent that is capable of discovering new items in Minecraft!\n",
    "- [WebVoyager](https://arxiv.org/abs/2401.13919) is an autonomous agent that is able to browse the web based on a user's request! Methods-wise, this is closer to ReAct, compared to Voyager/LLMCompiler. It just uses a vision model and some JS functions on top of the basic ReAct idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c432b973-33e4-425b-b475-3b99da9c07d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating a ReAct agent using pre-made functions\n",
    "\n",
    "`create_react_agent` is setup to allow us to do this. It works pretty poorly with LLaMa3.2 because the model has trouble providing outputs in a specific JSON format. For this reason, I don't really go in-depth into this agent.\n",
    "\n",
    "[create_react_agent docs](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99a0ab17-c74f-43c3-9d2c-76683be8f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e5c0cd2-e004-4153-bc5a-71428c55e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28723d0-3e87-4176-911e-32fac4f4d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70a227ac-9d2f-4fa3-bbcc-257f80edd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['llm-math'], llm=llm)\n",
    "agent = create_react_agent(llm, \n",
    "                           tools=tools, \n",
    "                           prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "459817fc-f7cc-4222-93c9-43bf12a43a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  +---------------------------------+  \n",
      "  | Parallel<agent_scratchpad>Input |  \n",
      "  +---------------------------------+  \n",
      "             **         **             \n",
      "           **             **           \n",
      "          *                 *          \n",
      "   +--------+          +-------------+ \n",
      "   | Lambda |          | Passthrough | \n",
      "   +--------+          +-------------+ \n",
      "             **         **             \n",
      "               **     **               \n",
      "                 *   *                 \n",
      " +----------------------------------+  \n",
      " | Parallel<agent_scratchpad>Output |  \n",
      " +----------------------------------+  \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "          +----------------+           \n",
      "          | PromptTemplate |           \n",
      "          +----------------+           \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "            +------------+             \n",
      "            | ChatOllama |             \n",
      "            +------------+             \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "   +------------------------------+    \n",
      "   | ReActSingleInputOutputParser |    \n",
      "   +------------------------------+    \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "+------------------------------------+ \n",
      "| ReActSingleInputOutputParserOutput | \n",
      "+------------------------------------+ \n"
     ]
    }
   ],
   "source": [
    "# Kinda hard to tell what's going on here, but yeah. The executor should take care of parsing the output, etc.\n",
    "print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7a42ed7-a280-437a-b5dc-d144692ca17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works, but the LLM is pretty bad at following instructions so this often errors.\n",
    "# agent_executor.invoke({\"input\": \"what is 365842068 + 3409568092?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef0aaf-5cf2-42df-bd75-a4ead254158d",
   "metadata": {},
   "source": [
    "We should probably figure out how AgentExecutor works, and what format we need the chain to be in to work with the AgentExecutor, but for now, let's move on to LangGraph so we can make custom agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9d166-56e7-4a47-b444-9b1d3812fb7a",
   "metadata": {},
   "source": [
    "# Remaking the agent in LangGraph\n",
    "\n",
    "I will remake the ReAct agent, adding fixes to help it work with an inferior model like LLaMa3.2.\n",
    "\n",
    "**Some Background**\n",
    "LangGraph is a library for building stateful, multi-actor applications with LLMs. It enables us to create things such as the ReAct prompting system, which loops back on itself many times.\n",
    "\n",
    "Let's recreate the ReAct agent, that can search the web and do math, but use our custom tools to make it work more smoothly with a smaller language model like LLaMa3.2. We will have these modifications:\n",
    "- we will update a scratchpad, containing the agents previous observations\n",
    "- we will be more lenient with parsing the agent's output\n",
    "\n",
    "Resources:\n",
    "- [MessagesPlaceholder](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html)\n",
    "- Most of this implementation is based on the [WebVoyager implementation by LangChain](https://www.youtube.com/watch?v=ylrew7qb8sQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab8bf990-d8a2-4d38-89ca-8d611ac6f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "# state\n",
    "from typing import List, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# misc\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b9ab0-a54e-4b62-a912-a23beaacd1c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Making State Types\n",
    "\n",
    "These types define the state that the graph will be using.\n",
    "\n",
    "The prediction will contain the agent's output, detailing the next action the agent should take. After we act on this prediction, we will put the response back into the 'observation' key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0fa1664-4665-4d56-bbdf-2dc1cf3a4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For searching the web/doing calculations this should be good.\n",
    "class Prediction(TypedDict):\n",
    "    action: str\n",
    "    args: Optional[str]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    str_output: str # llm output, this is not being used right now tbh\n",
    "    input: str # user request\n",
    "    prediction: Prediction # agent's output\n",
    "    scratchpad: List[BaseMessage]\n",
    "    observation: str # most recent response from a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c09d39-ee3b-47fc-b140-49cfb7f189a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Defining Tools\n",
    "\n",
    "These tools will be used by the LLM. I made some modifications to the tools, to work better with LLaMa3.2:\n",
    "- the search tool has an LLM Summarization built into it, to shorten the contents of the search. My reasoning is that distilling the search query can help the model better focus on the relevant parts, and the results of this search won't drown out other observations\n",
    "- The eval tool tries to correct agent input a bit, before performing the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2efe1382-41bf-493c-98c9-1d19636bc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddg_search = DuckDuckGoSearchRun()\n",
    "llm = ChatOllama(model=\"llama3.2\", max_tokens=4096)\n",
    "search_prompt_str = \"\"\"\n",
    "Please summarize these search results in the context of the following question. \n",
    "Be AS CONCISE AS POSSIBLE, and only include information that is relevant to answering the question.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "RESULTS: {search_results}\n",
    "\"\"\"\n",
    "search_prompt = PromptTemplate.from_template(search_prompt_str)\n",
    "summarization_chain = search_prompt | llm | StrOutputParser()\n",
    "\n",
    "# modified search with summarization chain\n",
    "def search(state: AgentState):\n",
    "    args = state['prediction']['args']\n",
    "    question = state['input']\n",
    "    if args is None:\n",
    "        return \"No arguments found for search tool. Please provide a search query!\"\n",
    "    search_results = ddg_search.invoke(args)\n",
    "    summary = summarization_chain.invoke(dict(search_results=search_results, question=state['input']))\n",
    "    return summary\n",
    "\n",
    "def evaluate_math(state: AgentState):\n",
    "    # We'll only evaluate basic math here\n",
    "    args = state['prediction']['args']\n",
    "    if args is None:\n",
    "        return \"No arguments found for math tool.\"\n",
    "    args = re.sub(r'[^0-9+-/*()<>]', '', args) # remove non-math related things\n",
    "    args = args.replace(',', '')\n",
    "    try:\n",
    "        result = eval(args)\n",
    "        return f\" = {result}\"\n",
    "    except SyntaxError:\n",
    "        return f\"ERROR: Math expression can only contain numbers and operators: {args}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49f74d1c-8422-4952-8fc5-eb9e4bea71c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' = True'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_math({'prediction': {'args': '3000 > 2000'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22eaff1d-5713-4b44-997f-cff873e1bfe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kanye West's net worth is approximately $400 million (as of June 2024), ranking him fourth on the list of top richest rappers in the world.\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search with summary\n",
    "search({'input': 'whats kanyes net worth', 'prediction': {'args': 'kanye net worth 2024'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff753ee-502d-427f-b779-327d5f851116",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ReAct components\n",
    "\n",
    "Parse will attempt to find the model's next {action, args} input.\n",
    "\n",
    "- The problem with the previous ReAct chain is that it is very strict when parsing the model's output, which is difficult for LLaMa3.2 to follow, so here, we will try to do a bit more parsing.\n",
    "- When updating the scratchpad, I will also append the prediction string that was called to past observations. I thought this might be useful in case the previous prediction failed with an error, then we can let the model debug it. I have not tested the model enough to see the effects of this, though\n",
    "- The LLM Chain will be explained below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03e1507f-3044-484f-8d34-70c314a79d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str):\n",
    "    text = text.replace('{{', '{')\n",
    "    text = text.replace('}}', '}')\n",
    "    try:\n",
    "        dict_in_text = re.search(r'\\{([^{}]*)\\}', text).group(1)\n",
    "        prediction = json.loads('{' + dict_in_text + '}')\n",
    "        if 'action' in prediction and 'args' in prediction:\n",
    "            return {'action': prediction['action'].strip(), 'args': prediction['args'].strip()}\n",
    "        else:\n",
    "            raise SyntaxError\n",
    "    except:\n",
    "        return {'action': 'retry', 'args': 'could not parse LLM output as JSON'}\n",
    "\n",
    "def update_scratchpad(state: AgentState):\n",
    "    # scratchpad will just contain one message here, which is the system message with observations\n",
    "    # this is inserted between the system prompt, and the human query\n",
    "    old = state.get('scratchpad')\n",
    "    if old:\n",
    "        txt = old[0].content\n",
    "        last_line = txt.rsplit(\"\\n\", 1)[-1]\n",
    "        step = int(re.match(r\"\\d+\", last_line).group()) + 1\n",
    "    else:\n",
    "        txt = \"Previous action observations:\\n\"\n",
    "        step = 1\n",
    "    txt += f\"\\n{step}. {state['prediction']} - {state['observation']}\"\n",
    "\n",
    "    return {**state, \"scratchpad\": [SystemMessage(content=txt)]}\n",
    "\n",
    "def get_llm_chain(debug=False):\n",
    "    llm = ChatOllama(model=\"llama3.2\", max_tokens=4096)\n",
    "    prompt_str = \"\"\"\n",
    "    Answer the following questions as best you can. Provide some reasoning, and then choose one of the following actions:\n",
    "\n",
    "    1. Evaluate a math expression. NOTE: this expression must only contain numbers, operators such as +-*/ and ()\n",
    "    2. Search the web\n",
    "    3. Respond with final answer, once previous action observations contain sufficient info to answer the question.\n",
    "\n",
    "    Correspondingly, Action should be returned as a JSON string, following these formats:\n",
    "    - {{ \"action\": \"eval\", \"args\": \"NUMERICAL EXPRESSION\" }}\n",
    "    - {{ \"action\": \"search\", \"args\": \"SEARCH QUERY\" }}\n",
    "    - {{ \"action\": \"answer\", \"args\": \"ANSWER\" }}\n",
    "    \n",
    "    Key Guidelines You MUST follow:\n",
    "\n",
    "    Execute only one action per iteration.\n",
    "    Keys and values in the Action JSON MUST be strings\n",
    "    \n",
    "    Your reply should strictly follow the format:\n",
    "\n",
    "    Thought: Your brief thoughts (briefly summarize the info that will help ANSWER)\n",
    "    Action: JSON formatted action\n",
    "    Then the User will provide:\n",
    "    Observation: Result of the action\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate(messages=[SystemMessage(content=prompt_str), \n",
    "                                          MessagesPlaceholder('scratchpad'),\n",
    "                                          HumanMessagePromptTemplate.from_template(\"Question: {input}\")], input_variables=['input'])\n",
    "    # Assign str_output for debugging purposes\n",
    "    if debug:\n",
    "        agent = (RunnablePassthrough.assign(str_output=prompt | llm | StrOutputParser())\n",
    "                 | RunnablePassthrough.assign(prediction=lambda state: parse(state['str_output'])))\n",
    "    else:\n",
    "        agent = (RunnablePassthrough.assign(prediction=prompt | llm | StrOutputParser() | parse))\n",
    "    return agent, prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0696d2-1492-4ec9-92ea-1eb687b48a1e",
   "metadata": {},
   "source": [
    "### LLM chain\n",
    "\n",
    "Here, note that we add scratchpad messages in between a system message explaining to the model what it should be doing, and a human message containing the input we want. We take advantage of chat model templates here. We can now add items to the model's scratchpad, and show it's effect on the generations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35dec9d3-7c42-4e39-ae96-ecfb3d724615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking chain with no previous observations\n",
      "\n",
      "RAW TEXT:\n",
      "Thought: Kanye West is a renowned musician, fashion designer, and entrepreneur. To determine his current net worth, I'll need to search for recent reports on his financial situation.\n",
      "\n",
      "Action:\n",
      "{{ \"action\": \"search\", \"args\": \"Kanye West net worth 2023\" }}\n",
      "\n",
      "ACTION:\n",
      "{'action': 'search', 'args': 'Kanye West net worth 2023'}\n",
      "\n",
      "#############################\n",
      "\n",
      "Invoking chain with artificial previous observations\n",
      "\n",
      "RAW TEXT:\n",
      "Thought: Since we already have information about Kanye West's net worth, it might be sufficient to answer this question directly.\n",
      "\n",
      "Action: {{ \"action\": \"answer\", \"args\": \"2 million dollars\" }}\n",
      "\n",
      "Please provide the observation result.\n",
      "\n",
      "ACTION:\n",
      "{'action': 'answer', 'args': '2 million dollars'}\n"
     ]
    }
   ],
   "source": [
    "chain, prompt = get_llm_chain(debug=True)\n",
    "\n",
    "# invoking the chain with no previous observations\n",
    "print(\"Invoking chain with no previous observations\")\n",
    "result = chain.invoke({\"input\": \"what is kanye west's net worth?\", \"scratchpad\": []})\n",
    "print(f\"\\nRAW TEXT:\\n{result['str_output']}\")\n",
    "print(f\"\\nACTION:\\n{result['prediction']}\")\n",
    "\n",
    "# invoking the chain with artificial previous observations\n",
    "print(\"\\n#############################\\n\")\n",
    "print(\"Invoking chain with artificial previous observations\")\n",
    "result = chain.invoke({\"input\": \"what is kanye west's net worth?\", \n",
    "              \"scratchpad\": [SystemMessage(content='Previous action observations:\\nKanye west has a net worth of 2 million dollars')]})\n",
    "print(f\"\\nRAW TEXT:\\n{result['str_output']}\")\n",
    "print(f\"\\nACTION:\\n{result['prediction']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3c036-e24f-4a4c-b6ee-3b8899bfd0b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Making the graph\n",
    "\n",
    "Here, we simply create nodes and edges to define the graph. Most of this is self-explanatory, since the graph is quite simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5b8fab28-6454-4c0b-8ed2-99506bd4968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent, _ = get_llm_chain(debug=True)\n",
    "\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Make agent node, set to the start state\n",
    "graph_builder.add_node(\"agent\", agent)\n",
    "graph_builder.add_edge(START, \"agent\")\n",
    "\n",
    "# Add update scratchpad node. When this is done, go back to the agent\n",
    "graph_builder.add_node(\"update_scratchpad\", update_scratchpad)\n",
    "graph_builder.add_edge(\"update_scratchpad\", \"agent\")\n",
    "\n",
    "# Add tools, update scratchpad after running tool\n",
    "tools = {'search': search, 'eval': evaluate_math}\n",
    "for node_name, tool in tools.items():\n",
    "    # This will run the tool and add the outputted observation to the state, with the key \"observation\"\n",
    "    # I think the original contents of the state will be kept, and we modify \"observation\" here when we put it into LangGraph\n",
    "    graph_builder.add_node(node_name, RunnableLambda(tool) | (lambda observation: {\"observation\": observation}))\n",
    "    graph_builder.add_edge(node_name, 'update_scratchpad')\n",
    "\n",
    "def select_tool(state: AgentState):\n",
    "    action = state['prediction']['action']\n",
    "    # Retry if unknown tool\n",
    "    if action not in ['search', 'eval', 'retry', 'answer']:\n",
    "        state['prediction'] = {'action': 'retry', 'args': 'unknown action'}\n",
    "    if action == 'answer':\n",
    "        return END\n",
    "    # so the agent won't actually see the error reason in the retry. We could route to update scratchpad to append this though\n",
    "    # if action == 'retry':\n",
    "    #     return 'agent'\n",
    "    if action == 'retry':\n",
    "        return 'update_scratchpad'\n",
    "    return action\n",
    "\n",
    "graph_builder.add_conditional_edges(\"agent\", select_tool)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fc9ef-606c-4ea1-bd3a-5e1fbe06aedc",
   "metadata": {},
   "source": [
    "When we call the agent, we stream the events, print relevant info and return results. We can inspect what `events` consist of for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e8fe758c-d739-4a3d-9889-ad9c64610385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_agent(question, max_steps=10):\n",
    "    # Basically yields intermediate results as soon as they are available\n",
    "    # Just copying code from WebVoyager for now.\n",
    "    event_stream = graph.stream({'input': question, 'scratchpad': []}, {'recursion_limit': max_steps})\n",
    "\n",
    "    steps = []\n",
    "    events = []\n",
    "    answer = None\n",
    "    try:\n",
    "        for event in event_stream:\n",
    "            events.append(event)\n",
    "            if \"agent\" not in event:\n",
    "                continue\n",
    "            pred = event[\"agent\"].get(\"prediction\") or {}\n",
    "            action = pred.get(\"action\")\n",
    "            args = pred.get(\"args\")\n",
    "            steps.append(f\"{len(steps) + 1}: {pred}\")\n",
    "            print(steps[-1])\n",
    "            if action == 'answer':\n",
    "                print(f'ANSWER: {args}')\n",
    "                break\n",
    "    finally:\n",
    "        return args, steps, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f8142e01-35b3-4934-bbf2-d1c19b7eaf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'action': 'search', 'args': 'Kanye West net worth'}\n",
      "2: {'action': 'answer', 'args': '800'}\n",
      "ANSWER: 800\n"
     ]
    }
   ],
   "source": [
    "args, steps, events = call_agent(\"If Kanye West's net worth were to double today, what would it be?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b58f464f-36dc-432f-8e7d-7daf873ef870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': {'observation': \"Kanye West's estimated net worth would double to $800 million if it were to double today.\"}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seems like events is just the list of the states as we pass through. \n",
    "# We can see that the summary LLM for the search results automatically did the math for us.\n",
    "events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "64840f9f-0f79-41c3-b16e-edd96500b95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: {'action': 'eval', 'args': '333000 * 2'}\n",
      "2: {'action': 'eval', 'args': '333000 * 2'}\n",
      "3: {'action': 'eval', 'args': '333000 * 2'}\n",
      "4: {'action': 'eval', 'args': '333000 * 2'}\n"
     ]
    }
   ],
   "source": [
    "# Seems like the agent gets stuck on computations. We could probably do some prompt engineering to change that, but for now, I will leave it as is.\n",
    "args, steps, events = call_agent(\"what is 333000 * 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c075eff-7aa6-4267-b70a-b23144000753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent': {'str_output': 'Thought: The previous action evaluation confirms that 333,000 multiplied by 2 equals 666,000. This observation will be used to answer the current question.\\n\\nAction: {{ \"action\": \"eval\", \"args\": \"333000 * 2\" }}\\n\\nObservation: 666000',\n",
       "  'input': 'what is 333000 * 2?',\n",
       "  'prediction': {'action': 'eval', 'args': '333000 * 2'},\n",
       "  'scratchpad': [SystemMessage(content=\"Previous action observations:\\n\\n1. {'action': 'eval', 'args': '333000 * 2'} -  = 666000\\n2. {'action': 'eval', 'args': '333000 * 2'} -  = 666000\\n3. {'action': 'eval', 'args': '333000 * 2'} -  = 666000\", additional_kwargs={}, response_metadata={})],\n",
       "  'observation': ' = 666000'}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that the model has the necessary info to give an answer, but is unable to generate the 'answer' action here.\n",
    "events[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc0503-8df8-46c8-8dd8-1a8bfba25df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
