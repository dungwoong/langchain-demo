{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcebd2a4-1a41-4e7a-85f1-92668eb253ab",
   "metadata": {},
   "source": [
    "[video](https://www.youtube.com/watch?v=1AmLD1aY7cM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c432b973-33e4-425b-b475-3b99da9c07d5",
   "metadata": {},
   "source": [
    "# Thought, Action, Observation\n",
    "\n",
    "Agent prompt\n",
    "- output format instructions\n",
    "- list of tools\n",
    "- chat history\n",
    "- examples\n",
    "\n",
    "TODO explain how this works here\n",
    "\n",
    "[create_react_agent docs](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99a0ab17-c74f-43c3-9d2c-76683be8f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e5c0cd2-e004-4153-bc5a-71428c55e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28723d0-3e87-4176-911e-32fac4f4d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70a227ac-9d2f-4fa3-bbcc-257f80edd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['llm-math'], llm=llm)\n",
    "agent = create_react_agent(llm, \n",
    "                                    tools=tools, \n",
    "                                    prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "459817fc-f7cc-4222-93c9-43bf12a43a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  +---------------------------------+  \n",
      "  | Parallel<agent_scratchpad>Input |  \n",
      "  +---------------------------------+  \n",
      "             **         **             \n",
      "           **             **           \n",
      "          *                 *          \n",
      "   +--------+          +-------------+ \n",
      "   | Lambda |          | Passthrough | \n",
      "   +--------+          +-------------+ \n",
      "             **         **             \n",
      "               **     **               \n",
      "                 *   *                 \n",
      " +----------------------------------+  \n",
      " | Parallel<agent_scratchpad>Output |  \n",
      " +----------------------------------+  \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "          +----------------+           \n",
      "          | PromptTemplate |           \n",
      "          +----------------+           \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "            +------------+             \n",
      "            | ChatOllama |             \n",
      "            +------------+             \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "   +------------------------------+    \n",
      "   | ReActSingleInputOutputParser |    \n",
      "   +------------------------------+    \n",
      "                   *                   \n",
      "                   *                   \n",
      "                   *                   \n",
      "+------------------------------------+ \n",
      "| ReActSingleInputOutputParserOutput | \n",
      "+------------------------------------+ \n"
     ]
    }
   ],
   "source": [
    "# Kinda hard to tell what's going on here, but yeah. The executor should take care of parsing the output, etc.\n",
    "print(agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7a42ed7-a280-437a-b5dc-d144692ca17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works, but the LLM is pretty bad at following instructions so this often errors.\n",
    "# agent_executor.invoke({\"input\": \"what is 365842068 + 3409568092?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef0aaf-5cf2-42df-bd75-a4ead254158d",
   "metadata": {},
   "source": [
    "We should probably figure out how AgentExecutor works, and what format we need the chain to be in to work with the AgentExecutor, but for now, let's move on to LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9d166-56e7-4a47-b444-9b1d3812fb7a",
   "metadata": {},
   "source": [
    "# LangGraph\n",
    "\n",
    "let's recreate a ReAct agent that can search the web and do math.\n",
    "\n",
    "- [MessagesPlaceholder](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ab8bf990-d8a2-4d38-89ca-8d611ac6f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts.chat import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# state\n",
    "from typing import List, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# misc\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0fa1664-4665-4d56-bbdf-2dc1cf3a4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For searching the web/doing calculations this should be good.\n",
    "class Prediction(TypedDict):\n",
    "    action: str\n",
    "    args: Optional[str]\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str # user request\n",
    "    prediction: Prediction # agent's output\n",
    "    scratchpad: List[BaseMessage]\n",
    "    observation: str # most recent response from a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2efe1382-41bf-493c-98c9-1d19636bc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddg_search = DuckDuckGoSearchRun()\n",
    "\n",
    "def search(state: AgentState):\n",
    "    args = state['prediction']['args']\n",
    "    if args is None:\n",
    "        return \"No arguments found for search tool. Please provide a search query!\"\n",
    "    return ddg_search.invoke(args)\n",
    "\n",
    "def eval(state: AgentState):\n",
    "    # We'll only evaluate basic math here\n",
    "    args = state['prediction']['args']\n",
    "    if args is None:\n",
    "        return \"No arguments found for math tool. Please provide a numerical expression!\"\n",
    "    args = re.sub(r'[^0-9+-/*()]', '', args) # remove non-math related things\n",
    "    try:\n",
    "        result = eval(args)\n",
    "        return f\"{args} = {result}\"\n",
    "    except SyntaxError:\n",
    "        return f\"Invalid math expression: {args}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "03e1507f-3044-484f-8d34-70c314a79d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str):\n",
    "    text = text.replace('{{', '{')\n",
    "    text = text.replace('}}', '}')\n",
    "    try:\n",
    "        dict_in_text = re.search(r'\\{([^{}]*)\\}', text).group(1)\n",
    "        prediction = json.loads('{' + dict_in_text + '}')\n",
    "        if 'action' in prediction and 'args' in prediction:\n",
    "            return {'action': prediction['action'].strip(), 'args': prediction['args'].strip()}\n",
    "        else:\n",
    "            raise SyntaxError\n",
    "    except:\n",
    "        return {'action': 'retry', 'args': 'could not parse LLM output as JSON'}\n",
    "\n",
    "def update_scratchpad(state: AgentState):\n",
    "    # scratchpad will just contain one message here\n",
    "    old = state.get('scratchpad')\n",
    "    if old:\n",
    "        txt = old[0].content\n",
    "        last_line = txt.rsplit(\"\\n\", 1)[-1]\n",
    "        step = int(re.match(r\"\\d+\", last_line).group()) + 1\n",
    "    else:\n",
    "        txt = \"Previous action observations:\\n\"\n",
    "        step = 1\n",
    "    txt += f\"\\n{step}. {state['observation']}\"\n",
    "\n",
    "    return {**state, \"scratchpad\": [SystemMessage(content=txt)]}\n",
    "\n",
    "def get_llm_chain():\n",
    "    llm = ChatOllama(model=\"llama3.2\", max_tokens=4096)\n",
    "    prompt_str = \"\"\"\n",
    "    Answer the following questions as best you can. Provide some reasoning, and then choose one of the following actions:\n",
    "\n",
    "    1. Evaluate a math expression\n",
    "    2. Search the web\n",
    "    3. Respond with final answer, once previous action observations contain sufficient info to answer the question.\n",
    "\n",
    "    Correspondingly, Action should be returned as a JSON string, following these formats:\n",
    "    - {{ \"action\": \"eval\", \"args\": \"NUMERICAL EXPRESSION\" }}\n",
    "    - {{ \"action\": \"search\", \"args\": \"SEARCH QUERY\" }}\n",
    "    - {{ \"action\": \"answer\", \"args\": \"ANSWER\" }}\n",
    "    \n",
    "    Key Guidelines You MUST follow:\n",
    "\n",
    "    Execute only one action per iteration.\n",
    "    Keys and values in the Action JSON MUST be strings\n",
    "    \n",
    "    Your reply should strictly follow the format:\n",
    "\n",
    "    Thought: Your brief thoughts (briefly summarize the info that will help ANSWER)\n",
    "    Action: JSON formatted action\n",
    "    Then the User will provide:\n",
    "    Observation: Result of the action\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate(messages=[SystemMessage(content=prompt_str), \n",
    "                                          MessagesPlaceholder('scratchpad'),\n",
    "                                          HumanMessagePromptTemplate.from_template(\"Question: {input}\")], input_variables=['input'])\n",
    "    # Assign str_output for debugging purposes\n",
    "    agent = (RunnablePassthrough.assign(str_output=prompt | llm | StrOutputParser())\n",
    "             | RunnablePassthrough.assign(prediction=lambda state: parse(state['str_output'])))\n",
    "    return agent, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "35dec9d3-7c42-4e39-ae96-ecfb3d724615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking chain with no previous observations\n",
      "\n",
      "RAW TEXT:\n",
      "Thought: Searching for recent Kanye West net worth data to ensure accuracy.\n",
      "\n",
      "Action: {{ \"action\": \"search\", \"args\": \"Kanye West net worth 2024\" }}\n",
      "\n",
      "ACTION:\n",
      "{'action': 'search', 'args': 'Kanye West net worth 2024'}\n",
      "\n",
      "#############################\n",
      "\n",
      "Invoking chain with artificial previous observations\n",
      "\n",
      "RAW TEXT:\n",
      "Thought: The observation contains enough information about Kanye West's net worth, so we can directly provide an answer.\n",
      "\n",
      "Action: {{ \"action\": \"answer\", \"args\": \"2 million dollars\" }}\n",
      "\n",
      "ACTION:\n",
      "{'action': 'answer', 'args': '2 million dollars'}\n"
     ]
    }
   ],
   "source": [
    "chain, prompt = get_llm_chain()\n",
    "\n",
    "# invoking the chain with no previous observations\n",
    "print(\"Invoking chain with no previous observations\")\n",
    "result = chain.invoke({\"input\": \"what is kanye west's net worth?\", \"scratchpad\": []})\n",
    "print(f\"\\nRAW TEXT:\\n{result['str_output']}\")\n",
    "print(f\"\\nACTION:\\n{result['prediction']}\")\n",
    "\n",
    "# invoking the chain with artificial previous observations\n",
    "print(\"\\n#############################\\n\")\n",
    "print(\"Invoking chain with artificial previous observations\")\n",
    "result = chain.invoke({\"input\": \"what is kanye west's net worth?\", \n",
    "              \"scratchpad\": [SystemMessage(content='Previous action observations:\\nKanye west has a net worth of 2 million dollars')]})\n",
    "print(f\"\\nRAW TEXT:\\n{result['str_output']}\")\n",
    "print(f\"\\nACTION:\\n{result['prediction']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9c06f3d4-7b7e-4c30-80fe-846ae96f979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"what is kanye west's net worth?\",\n",
       " 'scratchpad': [SystemMessage(content='Previous action observations:\\nKanye west has a net worth of 2 million dollars', additional_kwargs={}, response_metadata={})],\n",
       " 'str_output': 'Thought: Based on previous observation, Kanye West\\'s net worth should be consistent with the given value.\\n\\nAction: {{ \"action\": \"answer\", \"args\": \"2,000,000\" }}\\n\\nPlease provide the result of this action.',\n",
       " 'prediction': {'action': 'answer', 'args': '2,000,000'}}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fab28-6454-4c0b-8ed2-99506bd4968a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
